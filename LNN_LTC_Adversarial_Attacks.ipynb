{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c60cb75e-2f75-412d-81b7-f99eb27b01e0",
   "metadata": {},
   "source": [
    "## Comparison of adversarial robustness between Liquid Neural Network, CNN, and transformer architecture\n",
    "\n",
    "The LTC Liquid Neural Network Model is taken/forked from this tutorial repository: https://github.com/KPEKEP/LTCtutorial. This uses the following papers:\n",
    "\n",
    "*Step-by-Step Guide to Building an LTC Liquid Neural Network from Scratch*, Pavel Nakaznenko, 2024\n",
    "\n",
    "[Liquid Time-Constant Networks on Arxiv](https://arxiv.org/abs/2006.04439)\n",
    "\n",
    "Acknowledgement: The tutorial is heavily based on the reference [LTCCell implementation](https://github.com/mlech26l/ncps/blob/master/ncps/torch/ltc_cell.py), thanks to the authors of LNN.\n",
    "\n",
    "[Telegram channel: ToShoSeti](https://t.me/toshoseti)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4a788f-ca24-4f2b-9df0-28eea3d87d11",
   "metadata": {},
   "source": [
    "# LTC Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b6116-3c0a-4635-95c4-128b0815747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a634a2-a50d-49a3-ac1a-8582c093c08b",
   "metadata": {},
   "source": [
    "*Implementing the RandomWiring Class*\n",
    "\n",
    "The RandomWiring class is responsible for defining the connection architecture between neurons. It initializes random adjacency matrices for neuron connections and sensory inputs. Those are used as an arbitrary sparsity matrix later in LIFNeuralLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa25083-2ede-4ae6-9524-92244b0f872e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomWiring:\n",
    "    def __init__(self, input_dim, output_dim, neuron_count):\n",
    "        self.input_dim = input_dim  # Number of input features\n",
    "        self.output_dim = output_dim  # Number of output features\n",
    "        self.neuron_count = neuron_count  # Number of neurons in the layer\n",
    "        self.adjacency_matrix = np.random.uniform(0, 1, (neuron_count, neuron_count))  # Adjacency matrix for connections between neurons\n",
    "        self.sensory_adjacency_matrix = np.random.uniform(0, 1, (input_dim, neuron_count))  # Adjacency matrix for sensory inputs to neurons\n",
    "\n",
    "    def erev_initializer(self):\n",
    "        return np.random.uniform(-0.2, 0.2, (self.neuron_count, self.neuron_count))  # Initialize reversal potentials for neuron connections\n",
    "\n",
    "    def sensory_erev_initializer(self):\n",
    "        return np.random.uniform(-0.2, 0.2, (self.input_dim, self.neuron_count))  # Initialize reversal potentials for sensory inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddd71ad-1c3e-4b90-ac96-8835bcba9a9a",
   "metadata": {},
   "source": [
    "## Implementing the LIFNeuronLayer Class\n",
    "The LIFNeuronLayer class models the behavior of a layer of Leaky Integrate-and-Fire neurons. It initializes neuron parameters and defines the forward pass for computing neuron states. LIF dynamics are described using ODE and during the forward pass we solve the states using Euler Explicit method, described in the original article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7938b8-4841-4b11-8072-3bd3bf593baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIFNeuronLayer class explanation:\n",
    "\n",
    "\"\"\"\n",
    "The LIFNeuronLayer class is a PyTorch module that models a layer of Leaky Integrate-and-Fire (LIF) neurons, commonly used in spiking neural networks. It is designed to simulate the dynamics of neurons using an ordinary differential equation (ODE) solver. The class takes a wiring object as input, which contains the structural and connectivity information of the neurons, and initializes various parameters required for the simulation.\n",
    "\n",
    "In the constructor (__init__), the class initializes several neuron-specific parameters such as leak conductance (gleak), leak voltage (vleak), membrane capacitance (cm), and synaptic weights (w). These parameters are randomly initialized within predefined ranges to simulate biological variability. Additionally, sensory-specific parameters like sensory weights (sensory_w), sensory mean (sensory_mu), and sensory standard deviation (sensory_sigma) are also initialized. Fixed sparsity masks are created based on the adjacency matrices provided by the wiring object to enforce the connectivity structure.\n",
    "\n",
    "The forward method serves as the entry point for the layer's computation. It delegates the computation to the ode_solver method, which iteratively solves the ODE governing the neuron dynamics. The solver computes the membrane potential (v_pre) over multiple time steps (ode_unfolds) by incorporating sensory inputs, synaptic connections, and leak dynamics. Sensory inputs are pre-computed using a softplus activation function and a custom sigmoid function, which applies a mean shift and scaling to the inputs.\n",
    "\n",
    "Within the ODE solver, the neuron dynamics are updated iteratively. For each time step, the synaptic activations are computed based on the previous membrane potential, and the contributions from sensory and synaptic inputs are combined. The membrane potential is updated using a weighted sum of these inputs, leak dynamics, and membrane capacitance, ensuring numerical stability by adding a small epsilon value to the denominator.\n",
    "\n",
    "The sigmoid method is a helper function that applies a scaled and shifted sigmoid activation to the input voltage. This is used to model the non-linear response of neurons to their inputs. Overall, the LIFNeuronLayer class provides a biologically inspired simulation of spiking neurons, making it suitable for tasks involving spiking neural networks or neuromorphic computing.\n",
    "\"\"\"\n",
    "\n",
    "class LIFNeuronLayer(nn.Module):\n",
    "    def __init__(self, wiring, ode_unfolds=12, epsilon=1e-8):\n",
    "        super(LIFNeuronLayer, self).__init__()\n",
    "        self.wiring = wiring  # Wiring object containing connection information\n",
    "        self.ode_unfolds = ode_unfolds  # Number of ODE solver iterations\n",
    "        self.epsilon = epsilon  # Small value to avoid division by zero\n",
    "        self.softplus = nn.Softplus()  # Softplus activation function\n",
    "\n",
    "        # Initialization ranges for parameters\n",
    "        GLEAK_MIN, GLEAK_MAX = 0.001, 1.0\n",
    "        VLEAK_MIN, VLEAK_MAX = -0.2, 0.2\n",
    "        CM_MIN, CM_MAX = 0.4, 0.6\n",
    "        W_MIN, W_MAX = 0.001, 1.0\n",
    "        SIGMA_MIN, SIGMA_MAX = 3, 8\n",
    "        MU_MIN, MU_MAX = 0.3, 0.8\n",
    "        SENSORY_W_MIN, SENSORY_W_MAX = 0.001, 1.0\n",
    "        SENSORY_SIGMA_MIN, SENSORY_SIGMA_MAX = 3, 8\n",
    "        SENSORY_MU_MIN, SENSORY_MU_MAX = 0.3, 0.8\n",
    "\n",
    "        # Initialize neuron parameters with random values within specified ranges\n",
    "        self.gleak = nn.Parameter(torch.rand(wiring.neuron_count) * (GLEAK_MAX - GLEAK_MIN) + GLEAK_MIN)\n",
    "        self.vleak = nn.Parameter(torch.rand(wiring.neuron_count) * (VLEAK_MAX - VLEAK_MIN) + VLEAK_MIN)\n",
    "        self.cm = nn.Parameter(torch.rand(wiring.neuron_count) * (CM_MAX - CM_MIN) + CM_MIN)\n",
    "        self.w = nn.Parameter(torch.rand(wiring.neuron_count, wiring.neuron_count) * (W_MAX - W_MIN) + W_MIN)\n",
    "        self.sigma = nn.Parameter(torch.rand(wiring.neuron_count, wiring.neuron_count) * (SIGMA_MAX - SIGMA_MIN) + SIGMA_MIN)\n",
    "        self.mu = nn.Parameter(torch.rand(wiring.neuron_count, wiring.neuron_count) * (MU_MAX - MU_MIN) + MU_MIN)\n",
    "        self.erev = nn.Parameter(torch.Tensor(wiring.erev_initializer()))\n",
    "        \n",
    "        # Initialize sensory parameters with random values within specified ranges\n",
    "        self.sensory_w = nn.Parameter(torch.rand(wiring.input_dim, wiring.neuron_count) * (SENSORY_W_MAX - SENSORY_W_MIN) + SENSORY_W_MIN)\n",
    "        self.sensory_sigma = nn.Parameter(torch.rand(wiring.input_dim, wiring.neuron_count) * (SENSORY_SIGMA_MAX - SENSORY_SIGMA_MIN) + SENSORY_SIGMA_MIN)\n",
    "        self.sensory_mu = nn.Parameter(torch.rand(wiring.input_dim, wiring.neuron_count) * (SENSORY_MU_MAX - SENSORY_MU_MIN) + SENSORY_MU_MIN)\n",
    "        self.sensory_erev = nn.Parameter(torch.Tensor(wiring.sensory_erev_initializer()))\n",
    "\n",
    "        # Sparsity masks (fixed, non-learnable) based on the wiring adjacency matrices\n",
    "        self.sparsity_mask = torch.Tensor(np.abs(wiring.adjacency_matrix))\n",
    "        self.sensory_sparsity_mask = torch.Tensor(np.abs(wiring.sensory_adjacency_matrix))\n",
    "\n",
    "    def forward(self, inputs, state, elapsed_time=1.0):\n",
    "        return self.ode_solver(inputs, state, elapsed_time)\n",
    "\n",
    "    def ode_solver(self, inputs, state, elapsed_time):\n",
    "        v_pre = state  # Previous state (voltage)\n",
    "\n",
    "        # Pre-compute the effects of the sensory neurons\n",
    "        sensory_activation = self.softplus(self.sensory_w) * self.sigmoid(inputs, self.sensory_mu, self.sensory_sigma)\n",
    "        sensory_activation = sensory_activation * self.sensory_sparsity_mask\n",
    "        sensory_reversal_activation = sensory_activation * self.sensory_erev\n",
    "\n",
    "        # Calculate the numerator and denominator for sensory inputs\n",
    "        w_numerator_sensory = torch.sum(sensory_reversal_activation, dim=1)\n",
    "        w_denominator_sensory = torch.sum(sensory_activation, dim=1)\n",
    "\n",
    "        # Calculate membrane capacitance over time\n",
    "        cm_t = self.softplus(self.cm) / (elapsed_time / self.ode_unfolds)\n",
    "\n",
    "        # Initialize weights for neuron connections\n",
    "        w_param = self.softplus(self.w)\n",
    "        for _ in range(self.ode_unfolds):\n",
    "            # Activation based on previous state\n",
    "            w_activation = w_param * self.sigmoid(v_pre, self.mu, self.sigma)\n",
    "            w_activation = w_activation * self.sparsity_mask\n",
    "            reversal_activation = w_activation * self.erev\n",
    "\n",
    "            # Calculate the numerator and denominator for neuron connections\n",
    "            w_numerator = torch.sum(reversal_activation, dim=1) + w_numerator_sensory\n",
    "            w_denominator = torch.sum(w_activation, dim=1) + w_denominator_sensory\n",
    "\n",
    "            # Leak conductance and voltage calculations\n",
    "            gleak = self.softplus(self.gleak)\n",
    "            numerator = cm_t * v_pre + gleak * self.vleak + w_numerator\n",
    "            denominator = cm_t + gleak + w_denominator\n",
    "\n",
    "            # Update the state (voltage)\n",
    "            v_pre = numerator / (denominator + self.epsilon)\n",
    "\n",
    "        return v_pre\n",
    "\n",
    "    def sigmoid(self, v_pre, mu, sigma):\n",
    "        v_pre = torch.unsqueeze(v_pre, -1)  # Unsqueeze to match dimensions\n",
    "        activation = sigma * (v_pre - mu)  # Apply sigma and mean shift\n",
    "        return torch.sigmoid(activation)  # Apply sigmoid activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d292f2-b406-49e9-b857-c5e445abe57d",
   "metadata": {},
   "source": [
    "### Understanding the LIF Neural Layer\n",
    "\n",
    "The Leaky Integrate-and-Fire (LIF) neuron is a simple and widely used model in computational neuroscience. It simulates how biological neurons integrate incoming signals and fire when a threshold is reached. The LIF model captures the essential features of real neurons and is computationally efficient.\n",
    "\n",
    "#### Mathematical Formulation of LIF Neurons\n",
    "\n",
    "The LIF neuron can be described by the following differential equation:\n",
    "\n",
    "$$\\tau_m \\frac{dV(t)}{dt} = -V(t) + R_m I(t)$$\n",
    "\n",
    "Where:\n",
    "- $V(t)$ is the membrane potential at time $t$.\n",
    "- $\\tau_m$ is the membrane time constant.\n",
    "- $R_m$ is the membrane resistance.\n",
    "- $I(t)$ is the input current at time $t$.\n",
    "\n",
    "When the membrane potential $V(t)$ reaches a certain threshold $V_{\\text{th}}$, the neuron fires an action potential (or spike), and $V(t)$ is reset to a lower value, often $V_{\\text{reset}}$.\n",
    "\n",
    "#### Implementation in the LIFNeuronLayer Class\n",
    "\n",
    "The `LIFNeuronLayer` class in our implementation simulates a layer of LIF neurons with specific parameters for the membrane potential, conductance, and input weights. Let's break down its components and their roles.\n",
    "\n",
    "##### Initialization\n",
    "\n",
    "The class initializes several parameters that control the behavior of the neurons, including:\n",
    "- **gleak**: Leak conductance.\n",
    "- **vleak**: Leak voltage.\n",
    "- **cm**: Membrane capacitance.\n",
    "- **w, sigma, mu**: Parameters for the weights and activation functions.\n",
    "- **erev**: Reversal potentials for neuron connections.\n",
    "- **sensory_w, sensory_sigma, sensory_mu, sensory_erev**: Parameters for sensory inputs.\n",
    "\n",
    "#### Reversal Activation\n",
    "\n",
    "- **Reversal Activation**: This represents the influence of synaptic reversal potentials on the membrane potential. In biological neurons, the reversal potential is the voltage at which a specific ion's net flow through the membrane is zero. Incorporating reversal potentials into the model helps simulate realistic synaptic interactions.\n",
    "- **Calculation**: It involves multiplying the activation by the reversal potential matrix, which influences the neuron's state update during the forward pass. This mechanism helps integrate the effects of excitatory and inhibitory synapses.\n",
    "\n",
    "##### Forward Pass and ODE Solver\n",
    "\n",
    "The forward pass of the `LIFNeuronLayer` involves solving the differential equation that governs the membrane potential dynamics. This is done using an iterative approach with multiple ODE unfolds.\n",
    "\n",
    "Here’s a simplified explanation:\n",
    "1. **Pre-compute Sensory Effects**: Calculate the sensory activation and reversal activation based on the input.\n",
    "2. **ODE Solver Loop**: Iteratively update the neuron states using the ODE solver. This involves computing activations, applying sparsity masks, and updating the voltage states.\n",
    "\n",
    "##### Sigmoid Function\n",
    "\n",
    "The classic sigmoid function scales the inputs to a range between 0 and 1, which is essential for the activation of neurons. It is used both for the neuron connections and the sensory inputs.\n",
    "The sigmoid function in the LIFNeuronLayer class is customized to include parameters mu (mean) and sigma (scale). This customized implementation allows for more flexible and controlled activation behavior compared to the classic torch.sigmoid. \n",
    "\n",
    "1. **Parameter `mu` (Mean Shift)**:\n",
    "   - The `mu` parameter shifts the input voltage (`v_pre`). This shift allows the activation function to be centered around different mean values.\n",
    "   - Mathematically, `v_pre - mu` shifts the input such that the midpoint (where the sigmoid is 0.5) is not necessarily zero but `mu`.\n",
    "\n",
    "2. **Parameter `sigma` (Scale)**:\n",
    "   - The `sigma` parameter scales the input voltage (`v_pre`). This scaling controls the steepness of the sigmoid function.\n",
    "   - Mathematically, `sigma * (v_pre - mu)` adjusts the slope of the sigmoid curve. A larger `sigma` makes the sigmoid steeper, while a smaller `sigma` makes it more gradual.\n",
    "\n",
    "The customized sigmoid function is used to provide greater flexibility in the neural network's activation dynamics. Here's why this flexibility is important:\n",
    "\n",
    "1. **Biological Realism**:\n",
    "   - Biological neurons do not have a fixed activation threshold or response curve. The response curve can shift and scale depending on various factors.\n",
    "   - By incorporating `mu` and `sigma`, we can simulate this variability, making the model more biologically plausible.\n",
    "\n",
    "2. **Improved Learning**:\n",
    "   - Neural networks can benefit from adaptive activation functions. Different layers or neurons might require different activation behaviors to learn complex patterns effectively.\n",
    "   - The parameters `mu` and `sigma` can be learned during training, allowing the network to adjust its activation functions dynamically.\n",
    "\n",
    "3. **Enhanced Control**:\n",
    "   - In some cases, having control over the activation function's mean and scale can improve the network's ability to handle different input ranges and distributions.\n",
    "   - This customization can lead to better convergence and performance in certain tasks, especially in those involving varied and complex input signals.\n",
    "\n",
    "#### Why Random Adjacency and Sparsity Masks?\n",
    "\n",
    "- **Random Adjacency Matrix**: This matrix defines the connections between neurons in a random manner, simulating the complex and non-regular connectivity found in biological neural networks. It introduces variability and complexity in the network, which can help in learning more diverse patterns.\n",
    "- **Sparsity Mask**: This mask ensures that only certain connections are active, enforcing sparsity in the network. Sparse connections mimic the brain's efficient wiring, where not every neuron is connected to every other neuron, reducing computational load and preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b07a6d2-1493-4540-927a-268978f1a196",
   "metadata": {},
   "source": [
    "## Implementing the LTCCell Class\n",
    "The LTCCell class represents a single cell in the Liquid Time-Constant Recurrent Neural Network. It uses the LIFNeuronLayer to update neuron states.\n",
    "\n",
    "Note: we assume that the amount of neurons is always greater than the output dimmension, so we just trim them into outputs. Should that not be the case, feel free to use additional fully connected layer to project the hidden states into outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c20767-040b-4848-8ecf-efe85c009908",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LTCCell(nn.Module):\n",
    "    def __init__(self, wiring, in_features=None, ode_unfolds=6, epsilon=1e-8):\n",
    "        super(LTCCell, self).__init__()        \n",
    "        self.wiring = wiring  # Wiring object\n",
    "        self.ode_unfolds = ode_unfolds  # Number of ODE solver iterations\n",
    "        self.epsilon = epsilon  # Small value to avoid division by zero\n",
    "\n",
    "        self.neuron = LIFNeuronLayer(wiring, ode_unfolds, epsilon)  # Initialize LIFNeuron with the given wiring\n",
    "\n",
    "    def forward(self, inputs, states, elapsed_time=1.0):\n",
    "        next_state = self.neuron(inputs, states, elapsed_time)  # Compute the next state using the neuron model\n",
    "        outputs = next_state[:, :self.wiring.output_dim] # Map the state to the output dimensions\n",
    "        return outputs, next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcae71a-2f04-411d-8b41-483503761b01",
   "metadata": {},
   "source": [
    "## Implementing the LTCRNN Class\n",
    "The LTCRNN class constructs the recurrent neural network using multiple LTCCell instances. It processes sequences of inputs to produce sequences of outputs.\n",
    "\n",
    "Note: In this tutorial, the LTCRNN is supposed to be called one shot, for the whole sequence, hence the state initialization to zero in each forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baf2844-d177-4945-a456-c766c7eb93f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LTCRNN(nn.Module):\n",
    "    def __init__(self, wiring, input_dim, hidden_dim, output_dim):\n",
    "        super(LTCRNN, self).__init__()\n",
    "        self.cell = LTCCell(wiring, in_features=input_dim)  # Initialize LTCCell with wiring and input dimension\n",
    "        self.hidden_dim = hidden_dim  # Number of hidden neurons\n",
    "        self.output_dim = output_dim  # Number of output neurons\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        batch_size, seq_len, _ = inputs.size()  # Get batch size and sequence length from input dimensions\n",
    "        \n",
    "        states = torch.zeros(batch_size, self.hidden_dim)  # Initialize hidden states with zeros\n",
    "            \n",
    "        outputs = []  # List to store outputs for each time step\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            output, states = self.cell(inputs[:, t, :], states)  # Compute output and next state for each time step\n",
    "            outputs.append(output)  # Append the output to the list\n",
    "\n",
    "        result = torch.stack(outputs, dim=1)  # Stack the outputs along the sequence dimension\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d2fc0-2ad6-40a9-b5b3-d6ce9c8cfc0e",
   "metadata": {},
   "source": [
    "## Generating Spiral Data\n",
    "We will generate a dataset of spiral trajectories to train and evaluate our model. The generate_spiral_data function creates synthetic data points forming a spiral pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e2f4b6-53f8-44ea-b4e8-16e132a19d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate spiral data\n",
    "def generate_spiral_data(num_points, num_turns, noise = 2):\n",
    "    theta = np.linspace(0, num_turns * 2 * np.pi, num_points)\n",
    "    z = np.linspace(0, 1, num_points)\n",
    "    r = z\n",
    "    x = r * np.sin(theta) + noise * np.random.randn(*theta.shape) / num_points\n",
    "    y = r * np.cos(theta) + noise * np.random.randn(*theta.shape) / num_points\n",
    "    return np.stack([x, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb6eeb8-fece-479d-9a19-b247e7e68deb",
   "metadata": {},
   "source": [
    "## Training the Model\n",
    "Next, we set the hyperparameters and prepare the data for training. We define a training loop to train the model using the generated spiral data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebf55c7-e2b9-499b-b446-1478cc93b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 2 # Number of input dimensions\n",
    "hidden_dim = 8 # Number of hidden dimensions (number of neurons in LIFNeuralLayer)\n",
    "output_dim = 2 # Number of output dimensions\n",
    "num_points = 500 # Number of spiral points in dataset\n",
    "num_turns = 3 # Number of spiral turns\n",
    "learning_rate = 0.005\n",
    "num_epochs = 2000\n",
    "seq_len = 3 # Maximum length of the sample sequence\n",
    "batch_size = 32\n",
    "\n",
    "# Generate data\n",
    "data = generate_spiral_data(num_points, num_turns)\n",
    "all_inputs = data[:-1, :]\n",
    "all_targets = data[1:, :]\n",
    "\n",
    "# Prepare input and target sequences\n",
    "trajectory_count = max(1, len(all_inputs) - seq_len)\n",
    "train_inputs = [torch.FloatTensor(all_inputs[i:i + seq_len]) for i in range(trajectory_count)]\n",
    "train_targets = [torch.FloatTensor(all_targets[i:i + seq_len]) for i in range(trajectory_count)]\n",
    "\n",
    "# Shuffle and split the data for training\n",
    "random_train_indices = np.arange(len(train_inputs))\n",
    "np.random.shuffle(random_train_indices)\n",
    "train_split_index = int(len(random_train_indices) * 0.8)\n",
    "random_train_indices = random_train_indices[:train_split_index]\n",
    "\n",
    "# Function to create batches\n",
    "def create_batches(data_list, batch_size):\n",
    "    return [data_list[i:i + batch_size] for i in range(0, len(data_list), batch_size)]\n",
    "\n",
    "# Create input and target batches\n",
    "train_input_batches = create_batches(train_inputs, batch_size)\n",
    "train_target_batches = create_batches(train_targets, batch_size)\n",
    "\n",
    "# Initialize model\n",
    "wiring = RandomWiring(input_dim, output_dim, hidden_dim)\n",
    "lnn_model = LTCRNN(wiring, input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(lnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    lnn_model.train()    \n",
    "    total_loss = 0\n",
    "\n",
    "    # Iterate over batches\n",
    "    for x, y_target in zip(train_input_batches, train_target_batches):\n",
    "        optimizer.zero_grad()\n",
    "        x = torch.stack(x)  # Stack batch of sequences\n",
    "        y_target = torch.stack(y_target)  # Stack batch of targets\n",
    "        outputs = lnn_model(x)  # Forward pass through the lnn_model\n",
    "        loss = criterion(outputs, y_target)  # Compute loss\n",
    "\n",
    "        # Accumulate total loss and perform backward pass and optimization step\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss every 100 epochs and plot predictions\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        # Prediction and plotting\n",
    "        lnn_model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions = lnn_model(torch.FloatTensor(all_inputs).unsqueeze(0))\n",
    "            # np_predictions = predictions.squeeze(0).numpy()\n",
    "            np_predictions = np.array(predictions.squeeze(0).tolist())\n",
    "            val_loss = criterion(predictions, torch.FloatTensor(all_targets).unsqueeze(0))  # Compute loss\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Total train loss: {total_loss:.4f}, Total val loss: {val_loss:.4f}')\n",
    "\n",
    "        plt.plot(all_targets[:, 0], all_targets[:, 1], 'g-', label='True Path')\n",
    "        plt.plot(np_predictions[:, 0], np_predictions[:, 1], 'r-', label='Predicted Path')\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac0cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model (not the state dict)\n",
    "torch.save(lnn_model, \"lnn_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d95e8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "lnn_model = torch.load(\"lnn_model.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9525d0",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f64e185",
   "metadata": {},
   "source": [
    "To compare adversarial robustness of CNN against LNN (by running the same adversarial attacks on CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b157d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_channels=64, output_dim=2):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(input_dim, hidden_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(hidden_channels, hidden_channels, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(hidden_channels, output_dim, kernel_size=1)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # [B, C, T]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.conv3(x)\n",
    "        return x.permute(0, 2, 1)  # [B, T, C]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c031ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_dim = 2\n",
    "hidden_channels = 32\n",
    "output_dim = 2\n",
    "num_points = 500\n",
    "num_turns = 3\n",
    "learning_rate = 0.005\n",
    "num_epochs = 2000\n",
    "seq_len = 3\n",
    "batch_size = 32\n",
    "\n",
    "# Generate data\n",
    "data = generate_spiral_data(num_points, num_turns)\n",
    "all_inputs = data[:-1, :]\n",
    "all_targets = data[1:, :]\n",
    "\n",
    "# Prepare input and target sequences\n",
    "trajectory_count = max(1, len(all_inputs) - seq_len)\n",
    "train_inputs = [torch.FloatTensor(all_inputs[i:i + seq_len]) for i in range(trajectory_count)]\n",
    "train_targets = [torch.FloatTensor(all_targets[i:i + seq_len]) for i in range(trajectory_count)]\n",
    "\n",
    "# Shuffle and split\n",
    "random_train_indices = np.arange(len(train_inputs))\n",
    "np.random.shuffle(random_train_indices)\n",
    "train_split_index = int(len(random_train_indices) * 0.8)\n",
    "random_train_indices = random_train_indices[:train_split_index]\n",
    "\n",
    "train_input_batches = [train_inputs[i] for i in random_train_indices]\n",
    "train_target_batches = [train_targets[i] for i in random_train_indices]\n",
    "\n",
    "def create_batches(data_list, batch_size):\n",
    "    return [data_list[i:i + batch_size] for i in range(0, len(data_list), batch_size)]\n",
    "\n",
    "train_input_batches = create_batches(train_input_batches, batch_size)\n",
    "train_target_batches = create_batches(train_target_batches, batch_size)\n",
    "\n",
    "# Initialize CNN model\n",
    "cnn_model = CNN(input_dim=input_dim, hidden_channels=hidden_channels, output_dim=output_dim)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    cnn_model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for x_batch, y_batch in zip(train_input_batches, train_target_batches):\n",
    "        x = torch.stack(x_batch)  # [batch_size, seq_len, input_dim]\n",
    "        y = torch.stack(y_batch)  # [batch_size, seq_len, output_dim]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cnn_model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        total_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation and plotting every 100 epochs\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        cnn_model.eval()\n",
    "        with torch.no_grad():\n",
    "            test_input_tensor = torch.FloatTensor(all_inputs).unsqueeze(0)\n",
    "            predictions = cnn_model(test_input_tensor)\n",
    "            np_predictions = predictions.squeeze(0).numpy()\n",
    "            val_loss = criterion(predictions, torch.FloatTensor(all_targets).unsqueeze(0))\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {total_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "        plt.plot(all_targets[:, 0], all_targets[:, 1], 'g-', label='True Path')\n",
    "        plt.plot(np_predictions[:, 0], np_predictions[:, 1], 'r--', label='Predicted Path')\n",
    "        plt.xlim(-1.3, 1.3)\n",
    "        plt.ylim(-1.3, 1.3)\n",
    "        plt.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8efe1ac",
   "metadata": {},
   "source": [
    "On the final epoch:\n",
    "- CNN has a training loss of 0.0030 and validation loss of 0.0005\n",
    "- LNN has a training loss of 0.0031 and validation loss of 0.0004\n",
    "\n",
    "These are comparable neural networks (similar MSE loss values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model (not the state dict)\n",
    "torch.save(cnn_model, \"cnn_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c685c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "cnn_model = torch.load(\"cnn_model.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5ad2a9",
   "metadata": {},
   "source": [
    "# Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5630112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def infer_spiral(model, input_seq, target_seq=None):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.FloatTensor(input_seq).unsqueeze(0)  # Shape: [1, seq_len, input_dim]\n",
    "        predictions = model(x).squeeze(0).numpy()      # Shape: [seq_len, output_dim]\n",
    "\n",
    "    if target_seq is not None:\n",
    "        if isinstance(target_seq, torch.Tensor):\n",
    "            target_seq = target_seq.numpy()\n",
    "        \n",
    "        mse = mean_squared_error(target_seq, predictions)\n",
    "        mae = mean_absolute_error(target_seq, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        # Print metrics\n",
    "        print(f\"Inference Metrics:\")\n",
    "        print(f\"  MSE  = {mse:.6f}\")\n",
    "        print(f\"  RMSE = {rmse:.6f}\")\n",
    "        print(f\"  MAE  = {mae:.6f}\")\n",
    "\n",
    "        plt.plot(target_seq[:, 0], target_seq[:, 1], 'g-', label='True Path')\n",
    "    plt.plot(predictions[:, 0], predictions[:, 1], 'r--', label='Predicted Path')\n",
    "    plt.legend()\n",
    "    title = \"\"\n",
    "    if isinstance(model,LTCRNN):\n",
    "        title = \"LTC Model Inference\"\n",
    "    elif isinstance(model,CNN):\n",
    "        title = \"CNN Model Inference\"\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "# Change num_points and num_turns here to give input diff shape\n",
    "test_data = generate_spiral_data(num_points=200, num_turns=10000)\n",
    "\n",
    "# Prepare input and target pairs\n",
    "test_inputs = test_data[:-1, :]    # Inputs: from 0 to N-2\n",
    "test_targets = test_data[1:, :]    # Targets: from 1 to N-1\n",
    "\n",
    "\n",
    "# infer_spiral(model, all_inputs, all_targets)\n",
    "infer_spiral(lnn_model, test_inputs, test_targets)\n",
    "infer_spiral(cnn_model, test_inputs, test_targets)\n",
    "# infer_spiral(model, test_inputs[:3], test_targets[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c7368a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to display datapoints in target, predictions and adversarial predictions\n",
    "# For debugging attacks\n",
    "def display_datapoints(test_input, test_target, adv_output, skip=100):\n",
    "    assert (test_input.shape[0] == test_target.shape[0] == adv_output.shape[0]), \"Input, target and adversarial output must have the same number of samples\"\n",
    "\n",
    "    for i in range(0, test_input.shape[0], skip):\n",
    "        print(\"-\" * 60)\n",
    "        # print(f\"{'Datapoint':^20} {i:^5}\")\n",
    "        print(f\"{f'Datapoint {i}':^60}\")\n",
    "        print(f\"{'Target Value:':>30} {str(test_target[i]):>30}\")\n",
    "        print(f\"{'Original Prediction:':>30} {str(test_input[i]):>30}\")\n",
    "        print(f\"{'Adversarial Prediction:':>30} {str(adv_output[i]):>30}\")\n",
    "    print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7590cdd",
   "metadata": {},
   "source": [
    "# Robustness Metrics Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043f2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to calculate and display robustness metrics, given an adversarial output and original output\n",
    "\n",
    "def get_robustness_metrics(model, output, adv_output_tensor, target_tensor):\n",
    "    orig_loss = F.mse_loss(output, target_tensor).item()\n",
    "    adv_loss = F.mse_loss(adv_output_tensor, target_tensor).item()\n",
    "    robustness_ratio = (adv_loss - orig_loss) / (orig_loss + 1e-8)\n",
    "    deviation = torch.norm(output - adv_output_tensor).item()\n",
    "\n",
    "    # Print robustness metrics\n",
    "    model_type = 'LNN' if isinstance(model, LTCRNN) else 'CNN'\n",
    "    print(f\"[{model_type}] | Original Loss: {orig_loss:.4f} | Adversarial Loss: {adv_loss:.4f} | Degradation: {robustness_ratio:.2%} | Deviation: {deviation:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b9493b",
   "metadata": {},
   "source": [
    "# FGSM Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82520e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_manual_fgsm_attack(model, input_seq, target_seq, epsilon=0.05):\n",
    "    model.eval()\n",
    "\n",
    "    # Convert to tensors\n",
    "    input_tensor = torch.FloatTensor(input_seq).unsqueeze(0).requires_grad_(True)  # [1, seq_len, input_dim]\n",
    "    target_tensor = torch.FloatTensor(target_seq).unsqueeze(0)                      # [1, seq_len, output_dim]\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(input_tensor)\n",
    "    loss = F.mse_loss(output, target_tensor)\n",
    "\n",
    "    # Backward pass to compute gradients\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Generate perturbation using the sign of the gradient\n",
    "    perturbation = epsilon * input_tensor.grad.data.sign()\n",
    "    adv_input = input_tensor + perturbation\n",
    "    adv_input = adv_input.detach()\n",
    "\n",
    "    # Get adversarial output\n",
    "    adv_output = model(adv_input).squeeze(0).detach().numpy()\n",
    "    original_output = output.squeeze(0).detach().numpy()\n",
    "\n",
    "    # Display metrics\n",
    "    get_robustness_metrics(model, output, adv_output, target_tensor)\n",
    "\n",
    "    # Plot results\n",
    "    plt.plot(target_seq[:, 0], target_seq[:, 1], 'g-', label='True Path')\n",
    "    plt.plot(original_output[:, 0], original_output[:, 1], 'r--', label='Original Prediction')\n",
    "    plt.plot(adv_output[:, 0], adv_output[:, 1], 'b--', label='Adversarial Prediction')\n",
    "    plt.legend()\n",
    "    if isinstance(model,LTCRNN):\n",
    "        title = f\"Manual FGSM Attack (epsilon={epsilon}) on LTC Model\"\n",
    "    elif isinstance(model,CNN):\n",
    "        title = f\"Manual FGSM Attack (epsilon={epsilon}) on CNN\"\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    return adv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518d3620",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = generate_spiral_data(400, 4)\n",
    "test_input = test_data[:-1]\n",
    "test_target = test_data[1:]\n",
    "\n",
    "# Run attack on LNN\n",
    "run_manual_fgsm_attack(lnn_model, test_input, test_target, epsilon=0.05)\n",
    "\n",
    "# Run attack on CNN\n",
    "run_manual_fgsm_attack(cnn_model, test_input, test_target, epsilon=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3970e7",
   "metadata": {},
   "source": [
    "# PGD Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca912910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pgd_attack(model, input_seq, target_seq, epsilon=0.05, alpha=0.01, num_iter=10):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs\n",
    "    input_tensor = torch.FloatTensor(input_seq).unsqueeze(0)\n",
    "    target_tensor = torch.FloatTensor(target_seq).unsqueeze(0)\n",
    "\n",
    "    adv_input = input_tensor.clone().detach().requires_grad_(True)\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        output = model(adv_input)\n",
    "        loss = F.mse_loss(output, target_tensor)\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient ascent: move in the direction that increases loss\n",
    "        with torch.no_grad():\n",
    "            adv_input += alpha * adv_input.grad.sign()\n",
    "\n",
    "            # Project perturbation back into epsilon-ball of original input\n",
    "            perturbation = torch.clamp(adv_input - input_tensor, min=-epsilon, max=epsilon)\n",
    "            adv_input = torch.clamp(input_tensor + perturbation, min=input_tensor.min(), max=input_tensor.max())\n",
    "            adv_input.requires_grad_(True)\n",
    "\n",
    "    # Final prediction\n",
    "    adv_output = model(adv_input).squeeze(0).detach().numpy()\n",
    "    original_output = model(input_tensor).squeeze(0).detach().numpy()\n",
    "\n",
    "    # Display metrics\n",
    "    get_robustness_metrics(model, output, adv_output, target_tensor)\n",
    "\n",
    "\n",
    "    # Plot comparison\n",
    "    plt.plot(target_seq[:, 0], target_seq[:, 1], 'g-', label='True Path')\n",
    "    plt.plot(original_output[:, 0], original_output[:, 1], 'r--', label='Original Prediction')\n",
    "    plt.plot(adv_output[:, 0], adv_output[:, 1], 'b--', label='PGD Adversarial Prediction')\n",
    "    plt.legend()\n",
    "    if isinstance(model,LTCRNN):\n",
    "        title = f\"PGD Attack (epsilon={epsilon}, alpha={alpha}, iter={num_iter}) on LTC Model\"\n",
    "    elif isinstance(model,CNN):\n",
    "        title = f\"PGD Attack (epsilon={epsilon}, alpha={alpha}, iter={num_iter}) on CNN\"\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "    return adv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ca159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = generate_spiral_data(400, 4)\n",
    "test_input = test_data[:-1]\n",
    "test_target = test_data[1:]\n",
    "\n",
    "# Run attack on LNN\n",
    "run_pgd_attack(lnn_model, test_input, test_target, epsilon=0.05, alpha=0.01, num_iter=15)\n",
    "\n",
    "# Run attack on CNN\n",
    "run_pgd_attack(cnn_model, test_input, test_target, epsilon=0.05, alpha=0.01, num_iter=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5eeb717",
   "metadata": {},
   "source": [
    "# C&W Attack - not working yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e156087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cw_l2_attack(model, input_seq, target_seq, c=1e-3, kappa=0, num_iter=100, lr=1e-2):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare inputs\n",
    "    input_tensor = torch.FloatTensor(input_seq).unsqueeze(0)\n",
    "    target_tensor = torch.FloatTensor(target_seq).unsqueeze(0)\n",
    "\n",
    "    # Ensure inputs are in (0, 1) for atanh stability\n",
    "    eps = 1e-6\n",
    "    input_tensor_clamped = torch.clamp(input_tensor, eps, 1 - eps)\n",
    "    w_init = torch.atanh(2 * input_tensor_clamped - 1)\n",
    "\n",
    "    # Create optimization variable\n",
    "    w = w_init.clone().detach().requires_grad_(True)\n",
    "    optimizer = torch.optim.Adam([w], lr=lr)\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        adv_input = 0.5 * (torch.tanh(w) + 1)  # Ensure valid input range\n",
    "        output = model(adv_input)\n",
    "\n",
    "        # Loss: L2 distance + adversarial loss\n",
    "        l2_dist = torch.norm(adv_input - input_tensor, p=2)\n",
    "        adv_loss = -F.mse_loss(output, target_tensor, reduction='sum')  # make it deviate\n",
    "\n",
    "        loss = l2_dist + c * adv_loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Final adversarial input\n",
    "    adv_input = 0.5 * (torch.tanh(w) + 1).detach()\n",
    "    adv_output = model(adv_input).squeeze(0).detach().numpy()\n",
    "    original_output = model(input_tensor).squeeze(0).detach().numpy()\n",
    "\n",
    "    # Display metrics\n",
    "    get_robustness_metrics(model, output, adv_output, target_tensor)\n",
    "\n",
    "\n",
    "    # Plot comparison\n",
    "    plt.plot(target_seq[:, 0], target_seq[:, 1], 'g-', label='True Path')\n",
    "    plt.plot(original_output[:, 0], original_output[:, 1], 'r--', label='Original Prediction')\n",
    "    plt.plot(adv_output[:, 0], adv_output[:, 1], 'b--', label='CW Adversarial Prediction')\n",
    "    plt.legend()\n",
    "\n",
    "    if isinstance(model,LTCRNN):\n",
    "        title = f\"C&W L2 Attack (c={c}, iter={num_iter}) on LTC Model\"\n",
    "    elif isinstance(model,CNN):\n",
    "        title = f\"C&W L2 Attack (c={c}, iter={num_iter}) on CNN\"\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return adv_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f00bf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = generate_spiral_data(400, 4)\n",
    "test_input = test_data[:-1]\n",
    "test_target = test_data[1:]\n",
    "\n",
    "# Run attack on LNN\n",
    "adv_output = run_cw_l2_attack(lnn_model, test_input, test_target, c=1e-4, lr=1e-3)\n",
    "\n",
    "# Run attack on CNN\n",
    "adv_output = run_cw_l2_attack(cnn_model, test_input, test_target, c=1e-4, lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be2e90",
   "metadata": {},
   "source": [
    "# DeepFool Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3dfb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_deepfool_like_attack(model, input_seq, target_seq, max_iter=20, step_size=0.005):\n",
    "    model.eval()\n",
    "\n",
    "    input_tensor = torch.FloatTensor(input_seq).unsqueeze(0).requires_grad_(True)  # [1, T, D]\n",
    "    target_tensor = torch.FloatTensor(target_seq).unsqueeze(0)                     # [1, T, D]\n",
    "    adv_input = input_tensor.clone().detach().requires_grad_(True)\n",
    "\n",
    "    perturbation = torch.zeros_like(adv_input)\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        output = model(adv_input)\n",
    "        loss = F.mse_loss(output, target_tensor, reduction='sum')\n",
    "\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        grad = adv_input.grad.data\n",
    "        grad_norm = torch.norm(grad)\n",
    "\n",
    "        if grad_norm == 0:\n",
    "            break\n",
    "\n",
    "        # Compute minimal step in direction of gradient to move away from true output\n",
    "        # r_i = (loss.item() / (grad_norm ** 2)) * grad\n",
    "        r_i = step_size * grad / grad_norm\n",
    "        perturbation += r_i\n",
    "        # adv_input = input_tensor + (1 + overshoot) * perturbation\n",
    "        adv_input = input_tensor + perturbation\n",
    "        adv_input = adv_input.clone().detach().requires_grad_(True)\n",
    "\n",
    "    # Final outputs\n",
    "    adv_output = model(adv_input).squeeze(0).detach().numpy()\n",
    "    original_output = model(input_tensor).squeeze(0).detach().numpy()\n",
    "\n",
    "    # Plot results\n",
    "    plt.plot(target_seq[:, 0], target_seq[:, 1], 'g-', label='True Path')\n",
    "    plt.plot(original_output[:, 0], original_output[:, 1], 'r--', label='Original Prediction')\n",
    "    plt.plot(adv_output[:, 0], adv_output[:, 1], 'b--', label='DeepFool-like Adversarial')\n",
    "    plt.legend()\n",
    "\n",
    "    if isinstance(model,LTCRNN):\n",
    "        title = f\"DeepFool-Like Attack (iter={max_iter}, step_size={step_size}) on LTC Model\"\n",
    "    elif isinstance(model,CNN):\n",
    "        title = f\"DeepFool-Like Attack (iter={max_iter}, step_size={step_size}) on CNN\"\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return adv_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2cc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = generate_spiral_data(400, 4)\n",
    "test_input = test_data[:-1]\n",
    "test_target = test_data[1:]\n",
    "\n",
    "# Run attack on LNN\n",
    "adv_output_cw = run_deepfool_like_attack(lnn_model, test_input, test_target, step_size=0.005)\n",
    "\n",
    "# Run attack on CNN\n",
    "adv_output_cw = run_deepfool_like_attack(cnn_model, test_input, test_target, step_size=0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4080c42",
   "metadata": {},
   "source": [
    "# SPSA (Simultaneous Perturbation Stochastic Approximation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae706a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_spsa_attack(model, input_seq, target_seq, epsilon=0.05, num_iter=20, delta=0.01, learning_rate=0.01):\n",
    "    model.eval()\n",
    "\n",
    "    # Inputs\n",
    "    input_tensor = torch.FloatTensor(input_seq).unsqueeze(0)\n",
    "    target_tensor = torch.FloatTensor(target_seq).unsqueeze(0)\n",
    "\n",
    "    # Initialize adversarial input\n",
    "    adv_input = input_tensor.clone().detach()\n",
    "    \n",
    "    for _ in range(num_iter):\n",
    "        # Generate random perturbation vector (same shape as input)\n",
    "        perturb = torch.sign(torch.randn_like(input_tensor))\n",
    "\n",
    "        # Evaluate loss at positive and negative perturbations\n",
    "        input_plus = adv_input + delta * perturb\n",
    "        input_minus = adv_input - delta * perturb\n",
    "\n",
    "        input_plus = input_plus.detach()\n",
    "        input_minus = input_minus.detach()\n",
    "\n",
    "        loss_plus = F.mse_loss(model(input_plus), target_tensor, reduction='sum')\n",
    "        loss_minus = F.mse_loss(model(input_minus), target_tensor, reduction='sum')\n",
    "\n",
    "        # Approximate gradient (finite difference)\n",
    "        grad_estimate = (loss_plus - loss_minus) / (2 * delta) * perturb\n",
    "\n",
    "        # Update input in direction of increasing loss\n",
    "        adv_input = adv_input + learning_rate * torch.sign(grad_estimate)\n",
    "\n",
    "        # Clip to stay within epsilon of original input\n",
    "        perturbation = torch.clamp(adv_input - input_tensor, min=-epsilon, max=epsilon)\n",
    "        adv_input = torch.clamp(input_tensor + perturbation, min=input_tensor.min(), max=input_tensor.max())\n",
    "\n",
    "    # Final output\n",
    "    adv_output = model(adv_input).squeeze(0).detach().numpy()\n",
    "    original_output = model(input_tensor).squeeze(0).detach().numpy()\n",
    "\n",
    "\n",
    "    # Plot\n",
    "    plt.plot(target_seq[:, 0], target_seq[:, 1], 'g-', label='True Path')\n",
    "    plt.plot(original_output[:, 0], original_output[:, 1], 'r--', label='Original Prediction')\n",
    "    plt.plot(adv_output[:, 0], adv_output[:, 1], 'b--', label='SPSA Adversarial')\n",
    "    plt.legend()\n",
    "\n",
    "    if isinstance(model,LTCRNN):\n",
    "        title = f\"SPSA Attack (epsilon={epsilon}, iter={num_iter}, delta={delta}) on LTC Model\"\n",
    "    elif isinstance(model,CNN):\n",
    "        title = f\"SPSA Attack (epsilon={epsilon}, iter={num_iter}, delta={delta}) on CNN\"\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return adv_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661a0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = generate_spiral_data(400, 4)\n",
    "test_input = test_data[:-1]\n",
    "test_target = test_data[1:]\n",
    "\n",
    "# Run attack on LNN\n",
    "adv_output_cw = run_spsa_attack(lnn_model, test_input, test_target)\n",
    "\n",
    "# Run attack on CNN\n",
    "adv_output_cw = run_spsa_attack(cnn_model, test_input, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b19ab3",
   "metadata": {},
   "source": [
    "# *Temporal Sensitivity Attacks*\n",
    "Time-Warping Attack and Continuous-Time Adversarial Perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240c5933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for both temporal sensitivity attacks (time-warping attack and continuous-time adversarial perturbation)\n",
    "# Differentiable Linear interpolation\n",
    "\n",
    "\n",
    "def torch_interp1d(x, xp, fp):\n",
    "    \"\"\"\n",
    "    Differentiable linear interpolation: interpolates fp (at xp) to positions x.\n",
    "    \"\"\"\n",
    "    inds = torch.searchsorted(xp, x, right=True).clamp(min=1, max=len(xp) - 1)\n",
    "    x0, x1 = xp[inds - 1], xp[inds]\n",
    "    f0, f1 = fp[inds - 1], fp[inds]\n",
    "    slope = (f1 - f0) / (x1 - x0 + 1e-12)\n",
    "    return f0 + slope * (x - x0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a02458e",
   "metadata": {},
   "source": [
    "# Time-Warping Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0ccb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function implements a time-warping adversarial attack on a liquid neural network by optimizing small perturbations to the input time grid, rather than the input values themselves. It defines a set of learnable control points that deform the time axis, then resamples the original input sequence along the warped time grid using differentiable linear interpolation. The perturbations are trained via gradient ascent to maximize the model's output error with respect to the true target, exposing the model's sensitivity to temporal distortions.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_time_warping_attack(model, input_seq, target_seq, epsilon=0.1, num_control_points=10, num_iter=50, lr=1e-2):\n",
    "    model.eval()\n",
    "\n",
    "    # Prepare input and target tensors\n",
    "    input_seq = torch.FloatTensor(input_seq)\n",
    "    target_tensor = torch.FloatTensor(target_seq).unsqueeze(0)\n",
    "    T, D = input_seq.shape\n",
    "\n",
    "    time = torch.linspace(0, 1, T)\n",
    "    control_x = torch.linspace(0, 1, num_control_points)\n",
    "    delta_t = torch.zeros(num_control_points, requires_grad=True)\n",
    "\n",
    "    optimizer = torch.optim.Adam([delta_t], lr=lr)\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        # Perturb control points and ensure validity\n",
    "        warped_control_y = torch.clamp(control_x + torch.clamp(delta_t, -epsilon, epsilon), 0, 1)\n",
    "        warped_control_y_sorted, _ = torch.sort(warped_control_y)\n",
    "\n",
    "        # Interpolate full warped time\n",
    "        warped_time = torch_interp1d(time, control_x, warped_control_y_sorted)\n",
    "\n",
    "        # Interpolate each input dimension over warped time\n",
    "        input_seq_warped = torch.stack([\n",
    "            torch_interp1d(warped_time, time, input_seq[:, d])\n",
    "            for d in range(D)\n",
    "        ], dim=1)  # shape: [T, D]\n",
    "\n",
    "        adv_input = input_seq_warped.unsqueeze(0)  # shape: [1, T, D]\n",
    "        output = model(adv_input)\n",
    "        loss = F.mse_loss(output, target_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Final prediction\n",
    "    adv_output = model(adv_input).squeeze(0).detach().numpy()\n",
    "    original_output = model(input_seq.unsqueeze(0)).squeeze(0).detach().numpy()\n",
    "\n",
    "    # Plot\n",
    "    plt.plot(target_seq[:, 0], target_seq[:, 1], 'g-', label='True Path')\n",
    "    plt.plot(original_output[:, 0], original_output[:, 1], 'r--', label='Original Prediction')\n",
    "    plt.plot(adv_output[:, 0], adv_output[:, 1], 'b--', label='Time-Warped Adversarial')\n",
    "    plt.legend()\n",
    "\n",
    "    if isinstance(model,LTCRNN):\n",
    "        title = f\"Time-Warping Attack (ε={epsilon}, iter={num_iter}) on LTC Model\"\n",
    "    elif isinstance(model,CNN):\n",
    "        title = f\"Time-Warping Attack (ε={epsilon}, iter={num_iter}) on CNN\"\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return adv_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c8480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = generate_spiral_data(400, 4)\n",
    "test_input = test_data[:-1]\n",
    "test_target = test_data[1:]\n",
    "\n",
    "# Run attack on LNN\n",
    "adv_output_cw = run_time_warping_attack(lnn_model, test_input, test_target, epsilon=0.1, num_control_points=10, num_iter=50, lr=1e-2)\n",
    "\n",
    "# Run attack on CNN\n",
    "adv_output_cw = run_time_warping_attack(cnn_model, test_input, test_target, epsilon=0.1, num_control_points=10, num_iter=50, lr=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a83331a",
   "metadata": {},
   "source": [
    "# Continuous-Time Adversarial Perturbation Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7db690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def run_continuous_time_perturbation_attack(model, input_seq, target_seq, epsilon=0.1, num_control_points=10, num_iter=50, lr=1e-2):\n",
    "    \"\"\"\n",
    "    This function implements a continuous-time adversarial perturbation attack on a liquid neural network.\n",
    "    It defines a smooth additive perturbation function δ(t), parameterized by a small number of control points\n",
    "    across the input time sequence. The perturbation is optimized via gradient ascent to maximize the model's\n",
    "    output error, directly modifying the input signal over time while keeping the distortion bounded.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    # Convert to tensors\n",
    "    input_seq = torch.FloatTensor(input_seq)\n",
    "    target_tensor = torch.FloatTensor(target_seq).unsqueeze(0)\n",
    "    T, D = input_seq.shape\n",
    "\n",
    "    time = torch.linspace(0, 1, T)\n",
    "    control_x = torch.linspace(0, 1, num_control_points)\n",
    "    \n",
    "    # Learnable perturbations δ(t): shape [num_control_points, D]\n",
    "    delta_values = torch.zeros(num_control_points, D, requires_grad=True)\n",
    "    optimizer = torch.optim.Adam([delta_values], lr=lr)\n",
    "\n",
    "    for _ in range(num_iter):\n",
    "        # Interpolate δ(t) from control points to full sequence\n",
    "        perturbation = torch.stack([\n",
    "            torch_interp1d(time, control_x, delta_values[:, d])\n",
    "            for d in range(D)\n",
    "        ], dim=1)  # shape: [T, D]\n",
    "\n",
    "        # Clamp perturbation to stay within ±epsilon\n",
    "        perturbation = torch.clamp(perturbation, -epsilon, epsilon)\n",
    "\n",
    "        # Add perturbation to input\n",
    "        adv_input = (input_seq + perturbation).unsqueeze(0)  # shape: [1, T, D]\n",
    "        output = model(adv_input)\n",
    "        loss = F.mse_loss(output, target_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Final prediction\n",
    "    adv_output = model(adv_input).squeeze(0).detach().numpy()\n",
    "    original_output = model(input_seq.unsqueeze(0)).squeeze(0).detach().numpy()\n",
    "\n",
    "    # Plot\n",
    "    plt.plot(target_seq[:, 0], target_seq[:, 1], 'g-', label='True Path')\n",
    "    plt.plot(original_output[:, 0], original_output[:, 1], 'r--', label='Original Prediction')\n",
    "    plt.plot(adv_output[:, 0], adv_output[:, 1], 'b--', label='CT Adversarial Prediction')\n",
    "    plt.legend()\n",
    "\n",
    "    if isinstance(model,LTCRNN):\n",
    "        title = f\"Continuous-Time Perturbation Attack (ε={epsilon}, iter={num_iter}) on LTC Model\"\n",
    "    elif isinstance(model,CNN):\n",
    "        title = f\"Continuous-Time Perturbation Attack (ε={epsilon}, iter={num_iter}) on CNN\"\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return adv_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87549e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = generate_spiral_data(400, 4)\n",
    "test_input = test_data[:-1]\n",
    "test_target = test_data[1:]\n",
    "\n",
    "# Run attack on LNN\n",
    "adv_output_cw = run_continuous_time_perturbation_attack(lnn_model, test_input, test_target, epsilon=0.1, num_control_points=10, num_iter=50, lr=1e-2)\n",
    "\n",
    "# Run attack on CNN\n",
    "adv_output_cw = run_continuous_time_perturbation_attack(cnn_model, test_input, test_target, epsilon=0.1, num_control_points=10, num_iter=50, lr=1e-2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
